{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as  pd\n",
    "import re\n",
    "import ast\n",
    "import torch\n",
    "import torch.nn.functional as func\n",
    "import numpy as np\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def get_data(path):\n",
    "    with open(path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    json_formatted = '['\n",
    "    for line in lines:\n",
    "        json_formatted += line + ','\n",
    "    json_formatted = json_formatted[:-1] + ']'\n",
    "    json_formatted = re.sub('null', 'None', json_formatted)\n",
    "    return ast.literal_eval(json_formatted)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "       session_id           timestamp  user_id  product_id    event_type  offered_discount  purchase_id\n0             124 2021-02-16 14:51:39      102        1222  VIEW_PRODUCT                10          NaN\n1             124 2021-02-16 14:52:31      102        1072  VIEW_PRODUCT                10          NaN\n2             124 2021-02-16 14:54:35      102        1073  VIEW_PRODUCT                10          NaN\n3             124 2021-02-16 14:59:05      102        1201  VIEW_PRODUCT                10          NaN\n4             125 2020-06-10 19:14:06      102        1067  VIEW_PRODUCT                 0          NaN\n...           ...                 ...      ...         ...           ...               ...          ...\n51548       14658 2021-05-04 01:39:24      401        1010  VIEW_PRODUCT                 0          NaN\n51549       14658 2021-05-04 01:42:16      401        1006  VIEW_PRODUCT                 0          NaN\n51550       14658 2021-05-04 01:42:40      401        1011  VIEW_PRODUCT                 0          NaN\n51551       14658 2021-05-04 01:44:30      401        1013  VIEW_PRODUCT                 0          NaN\n51552       14658 2021-05-04 01:48:24      401        1009  VIEW_PRODUCT                 0          NaN\n\n[51553 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>session_id</th>\n      <th>timestamp</th>\n      <th>user_id</th>\n      <th>product_id</th>\n      <th>event_type</th>\n      <th>offered_discount</th>\n      <th>purchase_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>124</td>\n      <td>2021-02-16 14:51:39</td>\n      <td>102</td>\n      <td>1222</td>\n      <td>VIEW_PRODUCT</td>\n      <td>10</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>124</td>\n      <td>2021-02-16 14:52:31</td>\n      <td>102</td>\n      <td>1072</td>\n      <td>VIEW_PRODUCT</td>\n      <td>10</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>124</td>\n      <td>2021-02-16 14:54:35</td>\n      <td>102</td>\n      <td>1073</td>\n      <td>VIEW_PRODUCT</td>\n      <td>10</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>124</td>\n      <td>2021-02-16 14:59:05</td>\n      <td>102</td>\n      <td>1201</td>\n      <td>VIEW_PRODUCT</td>\n      <td>10</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>125</td>\n      <td>2020-06-10 19:14:06</td>\n      <td>102</td>\n      <td>1067</td>\n      <td>VIEW_PRODUCT</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>51548</th>\n      <td>14658</td>\n      <td>2021-05-04 01:39:24</td>\n      <td>401</td>\n      <td>1010</td>\n      <td>VIEW_PRODUCT</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>51549</th>\n      <td>14658</td>\n      <td>2021-05-04 01:42:16</td>\n      <td>401</td>\n      <td>1006</td>\n      <td>VIEW_PRODUCT</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>51550</th>\n      <td>14658</td>\n      <td>2021-05-04 01:42:40</td>\n      <td>401</td>\n      <td>1011</td>\n      <td>VIEW_PRODUCT</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>51551</th>\n      <td>14658</td>\n      <td>2021-05-04 01:44:30</td>\n      <td>401</td>\n      <td>1013</td>\n      <td>VIEW_PRODUCT</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>51552</th>\n      <td>14658</td>\n      <td>2021-05-04 01:48:24</td>\n      <td>401</td>\n      <td>1009</td>\n      <td>VIEW_PRODUCT</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>51553 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sessions = pd.DataFrame(get_data('sessions.jsonl'))\n",
    "df_sessions['timestamp'] = pd.to_datetime(df_sessions['timestamp'])\n",
    "df_sessions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def user_info(users):\n",
    "    df_info = copy.deepcopy(users)\n",
    "    df_info.drop(columns=['street'], inplace=True)\n",
    "    df_info['name'] = df_info['name'].str.split(' ').str.get(0)\n",
    "    df_info['name'] = df_info['name'].str.endswith('a')\n",
    "    df_info.rename(columns={'name':'sex'}, inplace=True)\n",
    "    df_info['sex'] = df_info['sex'].astype(int)\n",
    "\n",
    "    return df_info"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def categories_to_tensor(categorical, categories):\n",
    "    tensor = torch.zeros(categories.shape[0])\n",
    "    for category in categorical:\n",
    "        tensor += func.one_hot(torch.from_numpy(np.where(categories == category)[0])[0], num_classes=categories.shape[0])\n",
    "    return tensor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def merge_with_products(session, products):\n",
    "    session['purchase_id'] = session.loc[:,('purchase_id')].notna().astype(int)\n",
    "    session = pd.merge(session, products, on='product_id', how=\"left\")\n",
    "    session.rename(columns={'purchase_id':'purchase'}, inplace=True)\n",
    "    return session"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def set_spent_time(session):\n",
    "    session_end = session.iloc[-1]['timestamp']\n",
    "    session_start = session.iloc[0]['timestamp']\n",
    "    session['spent_time'] = session_end - session_start\n",
    "    return session"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def merge_session_to_one_row(session):\n",
    "    merged_session = pd.DataFrame(columns=['spent_time', 'offered_discount', 'sex', 'n_of_products_seen', 'sum_of_products_price', 'cheapest_prod', 'most_exp_prod'])\n",
    "    session_last = session.iloc[-1]\n",
    "    merged_session.loc[0] = [session_last['spent_time'].total_seconds(), session_last['offered_discount'], session_last['sex'], session['product_id'].unique().shape[0], session['price'].sum(), session['price'].min(), session['price'].max()]\n",
    "    return merged_session\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def set_root_category(session):\n",
    "    session['category_path'] = session['category_path'].str.split(';').str.get(0)\n",
    "    session.rename(columns={'category_path':'root_category'}, inplace=True)\n",
    "\n",
    "    return session"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def get_cities(users):\n",
    "    cities = users['city'].unique()\n",
    "    return cities"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def get_categories(products):\n",
    "    categories = products['category_path'].str.split(';').str.get(0).unique()\n",
    "    return categories"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def session_to_single_rows(session, products, users):\n",
    "    user_inf = user_info(users)\n",
    "    session = merge_with_products(session, products)\n",
    "\n",
    "    target = torch.tensor(session.iloc[-1]['purchase'], dtype=torch.float32)\n",
    "\n",
    "    session = set_root_category(session)\n",
    "    session.drop(columns=['event_type', 'product_name'], inplace=True)\n",
    "    session = session.merge(user_inf, on='user_id', how='left')\n",
    "    session.drop(columns='user_id', inplace=True)\n",
    "    session = set_spent_time(session)\n",
    "    session['day'] = session.iloc[0]['timestamp'].dayofweek\n",
    "    session['month'] = session.iloc[0]['timestamp'].month\n",
    "    categorical_columns_one = session.iloc[0][['city', 'day', 'month']]\n",
    "\n",
    "    categorical_columns_many = session['root_category'].unique()\n",
    "\n",
    "    merged_session = merge_session_to_one_row(session)\n",
    "\n",
    "    return merged_session, categorical_columns_one, categorical_columns_many, target"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def session_to_tensor(session):\n",
    "    products = pd.DataFrame(get_data('products.jsonl'))\n",
    "    users = pd.DataFrame(get_data('users.jsonl'))\n",
    "    merged_session, categorical_columns_one, categorical_columns_many, target = session_to_single_rows(session, products, users)\n",
    "    numerical_values = torch.from_numpy(merged_session.values)[0].float()\n",
    "\n",
    "    cities = get_cities(users)\n",
    "    categories = get_categories(products)\n",
    "\n",
    "    day = func.one_hot(torch.tensor(categorical_columns_one['day']), num_classes=7)\n",
    "    month = func.one_hot(torch.tensor(categorical_columns_one['month']-1), num_classes=12)\n",
    "    city = func.one_hot(torch.from_numpy(np.where(cities == categorical_columns_one['city'])[0])[0], num_classes=cities.shape[0])\n",
    "    cat_many = categories_to_tensor(categorical_columns_many, categories)\n",
    "    \n",
    "    categorical_values = torch.cat([cat_many, day, month, city])\n",
    "\n",
    "\n",
    "\n",
    "    return numerical_values, categorical_values, target"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def get_sessions_tensors(df_sessions):\n",
    "    sessions = df_sessions.groupby('session_id')\n",
    "    numerical_data = []\n",
    "    categorical_data = []\n",
    "    targets = []\n",
    "    sessions_id = df_sessions['session_id'].unique()\n",
    "    for i ,session_id in enumerate(sessions_id):\n",
    "        session = sessions.get_group(session_id)\n",
    "        session_tensor = session_to_tensor(session)\n",
    "        numerical_data.append(session_tensor[0])\n",
    "        categorical_data.append(session_tensor[1])\n",
    "        targets.append(session_tensor[2])\n",
    "\n",
    "    return torch.stack(numerical_data), torch.stack(categorical_data), torch.stack(targets)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_sessions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_9824/3919835835.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mdf_sessions_small\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdf_sessions\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0miloc\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;36m50\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mdf_sessions_small\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'df_sessions' is not defined"
     ]
    }
   ],
   "source": [
    "df_sessions_small = df_sessions.iloc[:50]\n",
    "df_sessions_small"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mateu\\AppData\\Local\\Temp/ipykernel_15548/2188711660.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session['purchase_id'] = session.loc[:,('purchase_id')].notna().astype(int)\n"
     ]
    }
   ],
   "source": [
    "numerical_data, categorical_data, targets = get_sessions_tensors(df_sessions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n        [1., 0., 0.,  ..., 0., 0., 0.],\n        [1., 0., 0.,  ..., 0., 0., 0.],\n        ...,\n        [0., 1., 0.,  ..., 0., 1., 0.],\n        [0., 1., 0.,  ..., 0., 1., 0.],\n        [0., 0., 1.,  ..., 0., 1., 0.]])"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0., 1., 1.,  ..., 0., 1., 0.])"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "train_indices = np.random.rand(len(numerical_data))>0.3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "train_numerical = numerical_data[train_indices]\n",
    "train_categorical = categorical_data[train_indices]\n",
    "train_targets = targets[train_indices]\n",
    "\n",
    "test_numerical = numerical_data[~train_indices]\n",
    "test_categorical = categorical_data[~train_indices]\n",
    "test_targets = targets[~train_indices]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "train_dataset = data.TensorDataset(train_numerical,train_categorical,train_targets)\n",
    "test_dataset = data.TensorDataset(test_numerical,test_categorical,test_targets)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model naiwny - bazujący na czasie trwania sesji"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "class NaiveClassifier:\n",
    "    def __init__(self):\n",
    "        self.time_mean = 0\n",
    "\n",
    "    def train(self, train_numerical):\n",
    "        self.time_mean = train_numerical[:, 0].mean()\n",
    "\n",
    "    def forward(self, numerical):\n",
    "        return (numerical[:, 0]>self.time_mean).int()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "naive = NaiveClassifier()\n",
    "naive.train(train_numerical)\n",
    "out = naive.forward(test_numerical)\n",
    "correct = out.eq(test_targets.view_as(out)).sum().item()\n",
    "total = test_numerical.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('naive.pkl', 'wb') as f:\n",
    "    pickle.dump(naive, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "0.4638985005767013"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct/total"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model bardziej zaawansowany - sieć neuronowa"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "class SessionClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SessionClassifier, self).__init__()\n",
    "        self.emb_layer = nn.Linear(categorical_data.shape[1], categorical_data.shape[1])\n",
    "        self.act_emb = nn.Tanh()\n",
    "        self.layer1 = nn.Linear(numerical_data.shape[1] + categorical_data.shape[1], 40)\n",
    "        self.act_1 =  nn.LeakyReLU()\n",
    "        self.d1 = nn.Dropout(0.4)\n",
    "        self.layer2 = nn.Linear(40, 20)\n",
    "        self.act_2 =  nn.LeakyReLU()\n",
    "        self.d2 = nn.Dropout(0.4)\n",
    "        self.layer3 = nn.Linear(20, 1)\n",
    "\n",
    "        self.f = nn.Sigmoid()\n",
    "    def forward(self, x, cat_x):\n",
    "        cat_x_embedded = self.emb_layer(cat_x)\n",
    "        cat_x_embedded = self.act_emb(cat_x_embedded)\n",
    "        x = torch.cat([x,cat_x_embedded],dim=1)\n",
    "        activation1 = self.act_1(self.layer1(x))\n",
    "        activation1 = self.d1(activation1)\n",
    "        activation2 = self.act_2(self.layer2(activation1))\n",
    "        activation2 = self.d2(activation2)\n",
    "        output = self.layer3(activation2)\n",
    "\n",
    "        output = self.f(output)\n",
    "        return output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "30"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_data.shape[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "7"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_data.shape[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda')"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "def get_accuracy(model, data_loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    for x, cat_x, labels in data_loader:\n",
    "        x, cat_x, labels = x.to(device), cat_x.to(device), labels.to(device)\n",
    "        output = model(x, cat_x)\n",
    "        pred = output>0.5\n",
    "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "        total += x.shape[0]\n",
    "    return correct / total"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss 0.703 test_acc: 0.524\n",
      "Epoch 5 loss 0.695 test_acc: 0.524\n",
      "Epoch 10 loss 0.691 test_acc: 0.524\n",
      "Epoch 15 loss 0.669 test_acc: 0.632\n",
      "Epoch 20 loss 0.63 test_acc: 0.782\n",
      "Epoch 25 loss 0.612 test_acc: 0.798\n",
      "Epoch 30 loss 0.604 test_acc: 0.809\n",
      "Epoch 35 loss 0.601 test_acc: 0.825\n",
      "Epoch 40 loss 0.595 test_acc: 0.826\n",
      "Epoch 45 loss 0.593 test_acc: 0.826\n",
      "Epoch 50 loss 0.59 test_acc: 0.828\n",
      "Epoch 55 loss 0.589 test_acc: 0.827\n",
      "Epoch 60 loss 0.59 test_acc: 0.828\n",
      "Epoch 65 loss 0.587 test_acc: 0.828\n",
      "Epoch 70 loss 0.586 test_acc: 0.827\n",
      "Epoch 75 loss 0.585 test_acc: 0.828\n",
      "Epoch 80 loss 0.587 test_acc: 0.827\n",
      "Epoch 85 loss 0.587 test_acc: 0.823\n",
      "Epoch 90 loss 0.585 test_acc: 0.827\n",
      "Epoch 95 loss 0.585 test_acc: 0.827\n",
      "Epoch 100 loss 0.585 test_acc: 0.827\n",
      "Final Training Accuracy: 0.8207843137254902\n",
      "Final Validation Accuracy: 0.8272202998846597\n"
     ]
    }
   ],
   "source": [
    "model = SessionClassifier().to(device)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-4)\n",
    "\n",
    "iters = []\n",
    "losses = []\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "for n in range(101):\n",
    "    epoch_losses = []\n",
    "    for x, cat_x, labels in iter(train_loader):\n",
    "        x, cat_x, labels = x.to(device), cat_x.to(device), labels.to(device)\n",
    "\n",
    "        model.train()\n",
    "        out = model(x, cat_x).squeeze()\n",
    "\n",
    "        loss = criterion(out, labels)\n",
    "        loss.backward()\n",
    "        epoch_losses.append(loss.item())\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    loss_mean = np.array(epoch_losses).mean()\n",
    "    iters.append(n)\n",
    "    losses.append(loss_mean)\n",
    "    test_acc = get_accuracy(model, test_loader)\n",
    "    if n % 5 == 0:\n",
    "        print(f\"Epoch {n} loss {loss_mean:.3} test_acc: {test_acc:.3}\")\n",
    "    train_acc.append(get_accuracy(model, train_loader)) # compute training accuracy\n",
    "    val_acc.append(test_acc)  # compute validation accuracy\n",
    "\n",
    "\n",
    "print(\"Final Training Accuracy: {}\".format(train_acc[-1]))\n",
    "print(\"Final Validation Accuracy: {}\".format(val_acc[-1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Wyznaczmy współczynnik alpha dla tego modelu (SessionClassifier)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "0.6542372881355932"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = test_dataset[test_dataset[:][2]==1]\n",
    "test_data = data.TensorDataset(test_data[0], test_data[1], test_data[2])\n",
    "test_data = torch.utils.data.DataLoader(test_data, batch_size=128, shuffle=False)\n",
    "get_accuracy(model, test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "df_sessions = pd.DataFrame(get_data('sessions.jsonl'))\n",
    "df_sessions['timestamp'] = pd.to_datetime(df_sessions['timestamp'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test mikroserwisu - wysyłanie requestów"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "pd.set_option('expand_frame_repr', False)\n",
    "\n",
    "def create_tensor_by_id(session_id, df):\n",
    "    df = df.where(df['session_id'] == session_id)\n",
    "    df[\"purchase_id\"] = df[\"purchase_id\"].notna().astype(int)\n",
    "    df = df.dropna()\n",
    "    print(df.head())\n",
    "    try:\n",
    "        numerical_data, categorical_data, targets = get_sessions_tensors(df)\n",
    "        return numerical_data, categorical_data, targets\n",
    "    except Exception as e:\n",
    "        print('Wrong id')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "def send_request_by_id(session_id, df, model='nn_model'):\n",
    "    numerical_data, categorical_data, targets = create_tensor_by_id(session_id, df)\n",
    "    data_set = {\n",
    "        'x_cat': categorical_data.tolist()[0],\n",
    "        'x_num': numerical_data.tolist()[0],\n",
    "        'model': model\n",
    "    }\n",
    "    json_request = json.dumps(data_set)\n",
    "    r = requests.post('http://localhost:5000/predict', json=json_request)\n",
    "    return r.json()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      session_id           timestamp  user_id  product_id    event_type  offered_discount  purchase_id\n",
      "5618      1685.0 2020-04-14 13:14:49    137.0      1047.0  VIEW_PRODUCT               5.0            0\n",
      "5619      1685.0 2020-04-14 13:18:55    137.0      1046.0  VIEW_PRODUCT               5.0            0\n",
      "5620      1685.0 2020-04-14 13:19:24    137.0      1041.0  VIEW_PRODUCT               5.0            0\n",
      "5621      1685.0 2020-04-14 13:21:06    137.0      1042.0  VIEW_PRODUCT               5.0            0\n",
      "5622      1685.0 2020-04-14 13:25:21    137.0      1084.0  VIEW_PRODUCT               5.0            0\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'certainty': 100.0, 'result': 0}"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = send_request_by_id(1685, df_sessions, 'nn_model')\n",
    "r"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}